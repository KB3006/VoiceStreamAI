<!DOCTYPE html>
<!--
  VoiceStreamAI Client Interface
  Real-time audio transcription using self-hosted Whisper and WebSocket

  Contributor:
  - Alessandro Saccoia - alessandro.saccoia@gmail.com
-->
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Audio Stream to WebSocket Server</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #f4f4f4;
      text-align: center;
    }

    h1 {
      color: #333;
    }

    .controls {
      margin: 20px auto;
      padding: 10px;
      width: 80%;
      display: flex;
      justify-content: space-around;
      align-items: center;
    }

    .control-group {
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .controls input, .controls button, .controls select {
      padding: 8px;
      margin: 5px;
      border: 1px solid #ddd;
      border-radius: 5px;
      font-size: 0.9em;
    }

    #transcription {
      margin: 20px auto;
      border: 1px solid #ddd;
      padding: 10px;
      width: 80%;
      height: 150px;
      overflow-y: auto;
      background: white;
    }

    #prompts {
      margin: 20px auto;
      border: 1px solid #ddd;
      padding: 10px;
      width: 80%;
      height: 150px;
      overflow-y: auto;
      background: white;
    }

    .label {
      font-size: 0.9em;
      color: #555;
      margin-bottom: 5px;
    }

    button {
      cursor: pointer;
    }

    .buffering-strategy-panel {
      margin-top: 10px;
    }

    /* ... existing styles ... */
    .hidden {
      display: none;
    }
  </style>
  <script>
    /**
 * VoiceStreamAI Client - WebSocket-based real-time transcription
 *
 * Contributor:
 * - Alessandro Saccoia - alessandro.saccoia@gmail.com
 */

let websocket;
let context;
let processor;
let globalStream;
let isRecording = false;

document.addEventListener("DOMContentLoaded", function() {
    const websocketAddress = document.querySelector('#websocketAddress');
    const roomId = document.querySelector('#roomId');
    const selectedLanguage = document.querySelector('#languageSelect');
    const selectedPerson = document.querySelector('#person');
    
    const websocketStatus = document.querySelector('#webSocketStatus');
    const connectButton = document.querySelector("#connectButton");
    const startButton = document.querySelector('#startButton');
    const stopButton = document.querySelector('#stopButton');
    const transcriptionDiv = document.querySelector('#transcription');
    const promptsDiv = document.querySelector('#prompts');
    const languageDiv = document.querySelector('#detected_language');
    const processingTimeDiv = document.querySelector('#processing_time');
    const panel = document.querySelector('#silence_at_end_of_chunk_options_panel');
    const selectedStrategy = document.querySelector('#bufferingStrategySelect');
    const chunk_length_seconds = document.querySelector('#chunk_length_seconds');
    const chunk_offset_seconds = document.querySelector('#chunk_offset_seconds');

    websocketAddress.addEventListener("input", resetWebsocketHandler);

    websocketAddress.addEventListener("keydown", (event) => {
        if (event.key === 'Enter') {
            event.preventDefault();
            connectWebsocketHandler();
        }
    });

    connectButton.addEventListener("click", connectWebsocketHandler);

    function resetWebsocketHandler() {
        if (isRecording) {
            stopRecordingHandler();
        }
        if (websocket && websocket.readyState === WebSocket.OPEN) {
            websocket.close();
        }
        connectButton.disabled = false;
    }

    function connectWebsocketHandler() {
        if (!websocketAddress.value) {
            console.log("WebSocket address is required.");
            return;
        }

        websocket = new WebSocket(websocketAddress.value);
        websocket.onopen = () => {
            console.log("WebSocket connection established");
            websocketStatus.textContent = 'Connected';
            startButton.disabled = false;
            connectButton.disabled = true;
        };
        websocket.onclose = event => {
            console.log("WebSocket connection closed", event);
            websocketStatus.textContent = 'Not Connected';
            startButton.disabled = true;
            stopButton.disabled = true;
            connectButton.disabled = false;
        };
        websocket.onmessage = event => {
            console.log("Message from server:", event.data);
            const transcript_data = JSON.parse(event.data);
            updateTranscription(transcript_data);
        };
    }
    
    function updateTranscription(transcript_data) {
        if (Array.isArray(transcript_data.words) && transcript_data.words.length > 0) {
            // Append words with color based on their probability
            transcript_data.words.forEach(wordData => {
                const span = document.createElement('span');
                const probability = wordData.probability;
                span.textContent = wordData.word + ' ';

                // Set the color based on the probability
                if (probability > 0.9) {
                    span.style.color = 'green';
                } else if (probability > 0.6) {
                    span.style.color = 'orange';
                } else {
                    span.style.color = 'red';
                }

                transcriptionDiv.appendChild(span);
            });

            // Add a new line at the end
            transcriptionDiv.appendChild(document.createElement('br'));
        } else {
            // Fallback to plain text
            const span = document.createElement('span');
            span.textContent = transcript_data.text;
            uploadText(selectedPerson.value,transcript_data.text);
            transcriptionDiv.appendChild(span);
            transcriptionDiv.appendChild(document.createElement('br'));
        }

        // Update the language information
        if (transcript_data.language && transcript_data.language_probability) {
            languageDiv.textContent = transcript_data.language + ' (' + transcript_data.language_probability.toFixed(2) + ')';
        } else {
            languageDiv.textContent = 'Not Supported';
        }

        // Update the processing time, if available
        if (transcript_data.processing_time) {
            processingTimeDiv.textContent = 'Processing time: ' + transcript_data.processing_time.toFixed(2) + ' seconds';
        }
    }

    startButton.addEventListener("click", startRecordingHandler);

    function startRecordingHandler() {
        if (isRecording) return;
        isRecording = true;

        context = new AudioContext();

        let onSuccess = async (stream) => {
            // Push user config to server
            let language = selectedLanguage.value !== 'multilingual' ? selectedLanguage.value : null;
            sendAudioConfig(language);

            globalStream = stream;
            const input = context.createMediaStreamSource(stream);
            const recordingNode = await setupRecordingWorkletNode();
            recordingNode.port.onmessage = (event) => {
                processAudio(event.data);
            };
            input.connect(recordingNode);
        };
        let onError = (error) => {
            console.error(error);
        };
        navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: true,
                autoGainControl: false,
                noiseSuppression: true,
                latency: 0
            }
        }).then(onSuccess, onError);

        // Disable start button and enable stop button
        startButton.disabled = true;
        stopButton.disabled = false;
    }

    async function setupRecordingWorkletNode() {
      const processorBlob = new Blob([`
            class RealtimeAudioProcessor extends AudioWorkletProcessor {
                constructor(options) {
                    super();
                }

                process(inputs, outputs, params) {
                    // ASR and VAD models typically require a mono audio.
                    this.port.postMessage(inputs[0][0]);
                    return true;
                }
            }

            registerProcessor('realtime-audio-processor', RealtimeAudioProcessor);
        `], { type: 'application/javascript' });

        const processorBlobURL = URL.createObjectURL(processorBlob);
        await context.audioWorklet.addModule(processorBlobURL);
        return new AudioWorkletNode(
            context,
            'realtime-audio-processor'
        );
    }

    stopButton.addEventListener("click", stopRecordingHandler);

    function uploadText(userType,text) {
    const url = 'https://devapi-asava.atirath.com/agentAssist/upload/'; // Change to match your deployment URL if different
    const formData = new FormData();
    formData.append('user_type', userType);
    formData.append('text', text);
    formData.append('roomId',roomId.value)

    fetch(url, {
        method: 'POST',
        body: formData
    })
    .then(response => response.json())
    .then(data => {
        console.log('Success:', data);
    })
    .catch((error) => {
        console.error('Error:', error);
    });
}

    function stopRecordingHandler() {
        if (!isRecording) return;
        isRecording = false;

        if (globalStream) {
            globalStream.getTracks().forEach(track => track.stop());
        }
        if (processor) {
            processor.disconnect();
            processor = null;
        }
        if (context) {
            context.close().then(() => context = null);
        }
        startButton.disabled = false;
        stopButton.disabled = true;
    }

    function sendAudioConfig(language) {
        let processingArgs = {};

        if (selectedStrategy.value === 'silence_at_end_of_chunk') {
            processingArgs = {
                chunk_length_seconds: parseFloat(chunk_length_seconds.value),
                chunk_offset_seconds: parseFloat(chunk_offset_seconds.value)
            };
        }

        const audioConfig = {
            type: 'config',
            data: {
                sampleRate: context.sampleRate,
                channels: 1,
                language: language,
                processing_strategy: selectedStrategy.value,
                processing_args: processingArgs
            }
        };

        websocket.send(JSON.stringify(audioConfig));
    }

    function processAudio(sampleData) {
        // ASR (Automatic Speech Recognition) and VAD (Voice Activity Detection)
        // models typically require mono audio with a sampling rate of 16 kHz,
        // represented as a signed int16 array type.
        //
        // Implementing changes to the sampling rate using JavaScript can reduce
        // computational costs on the server.
        const outputSampleRate = 16000;
        const decreaseResultBuffer = decreaseSampleRate(sampleData, context.sampleRate, outputSampleRate);
        const audioData = convertFloat32ToInt16(decreaseResultBuffer);

        if (websocket && websocket.readyState === WebSocket.OPEN) {
            websocket.send(audioData);
        }
    }

    function decreaseSampleRate(buffer, inputSampleRate, outputSampleRate) {
        if (inputSampleRate < outputSampleRate) {
            console.error("Sample rate too small.");
            return;
        } else if (inputSampleRate === outputSampleRate) {
            return;
        }

        let sampleRateRatio = inputSampleRate / outputSampleRate;
        let newLength = Math.ceil(buffer.length / sampleRateRatio);
        let result = new Float32Array(newLength);
        let offsetResult = 0;
        let offsetBuffer = 0;
        while (offsetResult < result.length) {
            let nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
            let accum = 0, count = 0;
            for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                accum += buffer[i];
                count++;
            }
            result[offsetResult] = accum / count;
            offsetResult++;
            offsetBuffer = nextOffsetBuffer;
        }
        return result;
    }

    function convertFloat32ToInt16(buffer) {
        let l = buffer.length;
        const buf = new Int16Array(l);
        while (l--) {
            buf[l] = Math.min(1, buffer[l]) * 0x7FFF;
        }
        return buf.buffer;
    }
    
    function getMyPrompts() {
        if(selectedPerson.value == "customer"){return;}
    const url = new URL('https://devapi-asava.atirath.com/agentAssist/getmyprompts');
    url.searchParams.append('user_type','agent'); // Add query parameter for user type
    url.searchParams.append('roomId',roomId.value); // Add query parameter for user type

    fetch(url)
    .then(response => response.json())
    .then(data => {
        if (data.prompt_id) {
            console.log('Prompt ID:', data.prompt_id);

            console.log('Prompt Text:', data.prompt_text);
            const span = document.createElement('span');
            span.textContent = data.prompt_text;
            promptsDiv.appendChild(span);
            promptsDiv.appendChild(document.createElement('br'));
            acknowledgePrompt(data.prompt_id);
        } else {
            console.log('No prompts available');
        }
    })
    .catch((error) => {
        console.error('Error:', error);
    });
}
if(selectedPerson.value == "agent")
{
setInterval(getMyPrompts,300);
}
    
function acknowledgePrompt(promptId) {
  fetch('/agentAssist/acknowledgeprompt', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded'
    },
    body: new URLSearchParams({
      'prompt_id': promptId
    })
  })
  .then(response => response.json())
  .then(data => {
    console.log(data.status);
  })
  .catch(error => {
    console.error('Error:', error);
  });
}

// Example usage



    function toggleBufferingStrategyPanel() {
        if (selectedStrategy.value === 'silence_at_end_of_chunk') {
            panel.classList.remove('hidden');
        } else {
            panel.classList.add('hidden');
        }
    }
});

  </script>
</head>
<body>
<h1>Transcribe a Web Audio Stream with Huggingface VAD + Whisper</h1>
<div class="controls">
  <div class="control-group">
    <label class="label" for="websocketAddress">WebSocket Address:</label>
    <input type="text" id="websocketAddress" value="https://devapi-asava.atirath.com/transcripting" readonly>
  </div>

  <div class="control-group">
    <label class="label" for="roomId">Room ID:</label>
    <input type="text" id="roomId" value="a1" readonly>
  </div>
  <div class="control-group">
    <label class="label" for="bufferingStrategySelect"
           onchange="toggleBufferingStrategyPanel()">Buffering Strategy:</label>
    <select id="bufferingStrategySelect">
      <option value="silence_at_end_of_chunk" selected>Silence at End of Chunk
      </option>
    </select>
  </div>
  <div id="silence_at_end_of_chunk_options_panel">
    <div class="control-group">
      <label class="label" for="chunk_length_seconds">Chunk Length (s):</label>
      <input type="number" id="chunk_length_seconds" value="3" min="1">
    </div>
    <div class="control-group">
      <label class="label" for="chunk_offset_seconds">Silence at the End of
        Chunk (s):</label>
      <input type="number" id="chunk_offset_seconds" value="0.1" min="0">
    </div>
  </div>
  <div class="control-group">
    <label class="label" for="languageSelect">Language:</label>
    <select id="languageSelect">
      <option value="multilingual">Multilingual</option>
      <option value="english">English</option>
      <option value="italian">Italian</option>
      <option value="spanish">Spanish</option>
      <option value="french">French</option>
      <option value="german">German</option>
      <option value="chinese">Chinese</option>
      <option value="arabic">Arabic</option>
      <option value="portuguese">Portuguese</option>
      <option value="russian">Russian</option>
      <option value="japanese">Japanese</option>
      <option value="dutch">Dutch</option>
      <option value="korean">Korean</option>
      <option value="hindi">Hindi</option>
      <option value="turkish">Turkish</option>
      <option value="swedish">Swedish</option>
      <option value="norwegian">Norwegian</option>
      <option value="danish">Danish</option>
      <option value="polish">Polish</option>
      <option value="finnish">Finnish</option>
      <option value="thai">Thai</option>
      <option value="czech">Czech</option>
      <option value="hungarian">Hungarian</option>
      <option value="greek">Greek</option>
    </select>
  </div>
  <div class="control-group">
    <label class="label" for="person">Person:</label>
    <select id="person">
      <option value="agent">Agent</option>
      <option value="customer">Customer</option>
      
    </select>
  </div>
  <button id="connectButton">Connect</button>
</div>
<button id="startButton" disabled>Start Streaming
</button>
<button id="stopButton" disabled>Stop Streaming
</button>
<div id="transcription"></div>
<div id="prompts"></div>
<br/>
<div>WebSocket: <span id="webSocketStatus">Not Connected</span></div>
<div>Detected Language: <span id="detected_language">Undefined</span></div>
<div>Last Processing Time: <span id="processing_time">Undefined</span></div>
</body>
</html>